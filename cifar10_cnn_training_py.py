# -*- coding: utf-8 -*-
"""cifar10_cnn_training.py.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qslzr6Aa2xwoMiZzq1dZZnAwric_kP7y
"""

pip install tensorflow

# Step 1: Import required libraries
import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
print(tf.__version__)

# Step 2: Load and prepare the CIFAR-10 dataset
print("Loading CIFAR-10 dataset...")
(x_train, y_train), (x_test, y_test) = cifar10.load_data()

# Normalize pixel values to range [0, 1]
x_train = x_train.astype('float32') / 255.0
x_test  = x_test.astype('float32')  / 255.0
# Convert class vectors to binary class matrices (one-hot encoding)  label 3 → [0,0,0,1,0,0,0,0,0,0]

# Bit depth	Max value
# 8-bit      255
# 10-bit	   1023
# 12-bit	   4095
# 16-bit	   65535
# 31-bit	   2,147,483,647

# by diving all values come in range of (0-1)
# min- max range also become in range of 0-1
# To make image pixel values small and consistent so the model learns better if it is not used then dark pixel ignored, bright become dominant

y_train = to_categorical(y_train, 10)
y_test  = to_categorical(y_test,  10)
print(f"Training data shape: {x_train.shape}")   # (50000, 32, 32, 3)
print(f"Test data shape:     {x_test.shape}")    # (10000, 32, 32, 3)

# Step 3: Define class names (for better visualization)
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

"""### **building cnn model**"""

model = models.Sequential([ # sequential creates a stacked model , layers are created
    # First Convolutional Block
    layers.Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)),
    layers.BatchNormalization(),
    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    # Second Convolutional Block
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'), # padding = same keeps height and width of image same as input
    layers.BatchNormalization(),
    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    layers.BatchNormalization(),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),
    # Flatten and Dense layers
    layers.Flatten(),
    layers.Dense(512, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.5),
      # Output layer – 10 classes
    layers.Dense(10, activation='softmax')
])

"""- instead of sequential we can use functional API
  - DRAWS FLOWCHART OF A NETWORK
- model subclassing

### compiling the model

Adaptive Moment Estimation
"""

model.compile(optimizer='adam',   #Adam decides how the model updates its weights. learns from  mistakes
              loss='categorical_crossentropy', #It is a loss function
              metrics=['accuracy'])
model.summary()   # Print model architecture

# Step 6: Train the model
print("\nTraining the model...")
history = model.fit(x_train, y_train,
                    epochs=20,               # increase to 30–50 for better results
                    batch_size=128,
                    validation_data=(x_test, y_test),
                    verbose=1)

# Step 7: Evaluate on test set
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)
print(f"\nTest accuracy: {test_acc:.4f}  ({test_acc*100:.2f}%)")
# Step 8: Visualize training history
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()
plt.show()

# Step 9: Make predictions on a few test images (visual check)
num_images = 8
predictions = model.predict(x_test[:num_images])
predicted_classes = np.argmax(predictions, axis=1)
true_classes = np.argmax(y_test[:num_images], axis=1)

plt.figure(figsize=(15, 8))
for i in range(num_images):
    plt.subplot(2, 4, i+1)
    plt.imshow(x_test[i])
    plt.title(f"Pred: {class_names[predicted_classes[i]]}\nTrue: {class_names[true_classes[i]]}",
              color=("green" if predicted_classes[i] == true_classes[i] else "red"))
    plt.axis('off')
plt.tight_layout()
plt.show()
# Optional: Save the model
# model.save("basic_cifar10_cnn.h5")

